# ğŸ¨ BrandChecker - AI-Powered Brand Analysis System

Ein umfassendes Docker-basiertes System fÃ¼r automatisierte Brand-Analyse mit KI-gestÃ¼tzter PDF-Verarbeitung, Farb- und Font-Erkennung sowie Logo-Detection. **Jetzt mit integrierter LLM-FunktionalitÃ¤t fÃ¼r intelligente Brand-Guideline-Befragung!**

[![Docker](https://img.shields.io/badge/Docker-Ready-blue?logo=docker)](https://www.docker.com/)
[![Python](https://img.shields.io/badge/Python-3.9+-green?logo=python)](https://python.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue?logo=postgresql)](https://postgresql.org/)
[![N8N](https://img.shields.io/badge/N8N-Workflow-orange?logo=n8n)](https://n8n.io/)
[![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o-green?logo=openai)](https://openai.com/)

## ğŸš€ Features

- **ğŸ¤– KI-gestÃ¼tzte PDF-Analyse** mit automatischer Text-, Font- und Farbextraktion
- **ğŸ¯ Intelligente Logo-Erkennung** mit Vector-basierter Ã„hnlichkeitssuche
- **ğŸ“Š Umfassende Brand-Analyse** mit Layout- und Design-Bewertung
- **ğŸ”„ N8N Workflow-Integration** fÃ¼r automatisierte Prozesse
- **ğŸ—„ï¸ PostgreSQL Datenbank** mit Vector Embeddings fÃ¼r semantische Suche
- **ğŸ“ˆ Automatische Report-Generierung** mit visuellen Analysen
- **ğŸ§  LLM-Integration** mit GPT-5 fÃ¼r intelligente Brand-Guideline-Befragung
- **ğŸ” Semantische Suche** in Brand Guidelines mit OpenAI Embeddings
- **ğŸ’¬ Chat-Interface** fÃ¼r natÃ¼rliche Sprachinteraktion mit Brand-Daten
- **ğŸ¨ Farb-Ã„hnlichkeits-Bewertung** mit HSV-basierten Algorithmen fÃ¼r intelligente Farb-Matching
- **ğŸ“Š Brand-Compliance-Analyzer** fÃ¼r automatische KonformitÃ¤tsbewertung
- **âš¡ Streaming-UnterstÃ¼tzung** fÃ¼r Echtzeit-Antworten in n8n Workflows
- **ğŸ–¼ï¸ Bildanalyse** mit GPT-4o Vision fÃ¼r Icons, Logos und Grafiken
- **ğŸ“ SVG-UnterstÃ¼tzung** mit automatischer PNG-Konvertierung
- **ğŸ¯ Icon-Klassifizierung** mit detaillierter Beschreibung und Brand-Compliance

## Services

### n8n Service
- **Port**: 5680 (extern) -> 5678 (intern)
- **Login**: admin / brandchecker123
- **URL**: http://localhost:5680

### Python Service
- **Port**: 8000
- **Features**: PDF Text-Extraktion mit pdfminer.six
- **URL**: http://localhost:8000

### LLM API Service (NEU!)
- **Port**: 8001
- **Features**: KI-gestÃ¼tzte Brand-Guideline-Befragung mit GPT-5
- **URL**: http://localhost:8001
- **Endpoints**: `/api/ask`, `/api/search`, `/api/embeddings/generate`
- **Streaming**: UnterstÃ¼tzt Echtzeit-Antworten fÃ¼r n8n Integration
- **Farb-Ã„hnlichkeits**: HSV-basierte Farb-Matching-Algorithmen

### Image API Service (NEU!)
- **Port**: 8002
- **Features**: Bildanalyse mit GPT-4o Vision fÃ¼r Icons, Logos und Grafiken
- **URL**: http://localhost:8002
- **Endpoints**: `/api/analyze-image`
- **SVG-Support**: Automatische Konvertierung von SVG zu PNG
- **Brand Compliance**: Automatische Bewertung von Brand Guide Bildern (100/100)

### PostgreSQL mit pgvector
- **Port**: 5433
- **Features**: Vector Embeddings fÃ¼r semantische Suche
- **pgvector**: FÃ¼r effiziente Ã„hnlichkeitssuche in Brand Guidelines

## Installation und Start

```bash
# 1. OpenAI API Key setzen (erforderlich fÃ¼r LLM-Features)
export OPENAI_API_KEY="your_openai_api_key_here"

# 2. Container starten
docker-compose up -d

# 3. Logs anzeigen
docker-compose logs -f

# 4. Container stoppen
docker-compose down
```

### ğŸ”‘ Erforderliche Umgebungsvariablen

FÃ¼r die LLM-FunktionalitÃ¤t benÃ¶tigen Sie einen OpenAI API Key:

```bash
# .env Datei erstellen oder Umgebungsvariable setzen
OPENAI_API_KEY=sk-proj-your-key-here
```

## Python API Endpoints

### Health Check
```bash
curl http://localhost:8000/health
```

### PDF Text Extraktion
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-text
```

### Erweiterte PDF Text Extraktion
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-text-advanced
```

### PDF Font Extraktion
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-fonts
```

### PDF Farben Extraktion
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-colors
```

### PDF Bilder Extraktion
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-images
```

### PDF Layout Analyse
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-layout
```

### PDF Metadaten Extraktion
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/extract-metadata
```

### Komplette PDF Analyse
```bash
curl -X POST -F "file=@document.pdf" http://localhost:8000/analyze-complete
```

### Service Information
```bash
curl http://localhost:8000/info
```

## ğŸ§  LLM API Endpoints (NEU!)

### Brand-Guideline-Befragung
```bash
curl -X POST -H "Content-Type: application/json" \
  -d '{"question": "Welche Farben sind fÃ¼r Bosch erlaubt?", "brand_id": "brand-uuid"}' \
  http://localhost:8001/api/ask
```

### Semantische Suche
```bash
curl -X POST -H "Content-Type: application/json" \
  -d '{"query": "Bosch Farben", "brand_id": "brand-uuid"}' \
  http://localhost:8001/api/search
```

### Embeddings generieren
```bash
curl -X POST http://localhost:8001/api/embeddings/generate
```

### Brand-Informationen abrufen
```bash
curl http://localhost:8001/api/brands
curl http://localhost:8001/api/brands/{brand_id}/assets
curl http://localhost:8001/api/brands/{brand_id}/guidelines
```

### Streaming-Antworten (NEU!)
```bash
curl -X POST -H "Content-Type: application/json" \
  -d '{"question": "Welche Farben sind fÃ¼r Bosch erlaubt?", "brand_id": "brand-uuid", "stream": true}' \
  http://localhost:8001/api/ask
```

## ğŸ¨ Erweiterte Brand-Analyse Features (NEU!)

### Farb-Ã„hnlichkeits-Bewertung
Das System kann jetzt Farben basierend auf HSV-Ã„hnlichkeits-Algorithmen bewerten:

```python
# Beispiel: Ã„hnlichkeit zwischen Farben berechnen
similarity = analyzer.color_similarity("#007bc0", "#0088cc")  # 99.3% Ã„hnlichkeit
best_match = analyzer.find_best_color_match("#0088cc")  # Findet Bosch Blau 50
```

### Brand-Compliance-Analyzer
Automatische KonformitÃ¤tsbewertung fÃ¼r PDF-Dokumente:

```python
from brand_compliance_analyzer import BrandComplianceAnalyzer

analyzer = BrandComplianceAnalyzer()
result = analyzer.analyze_compliance(analysis_data)

# Ergebnis enthÃ¤lt:
# - Farb-Compliance mit Ã„hnlichkeits-Bewertung
# - Font-Compliance
# - Gesamtbewertung (0-100 Punkte)
# - Konkrete Empfehlungen
```

### n8n Integration mit Streaming
FÃ¼r n8n Workflows mit Echtzeit-Antworten:

```json
{
  "toolDescription": "Bosch Brand Guidelines mit Streaming",
  "method": "POST",
  "url": "http://brandchecker-llm-api:8001/api/ask",
  "bodyParameters": {
    "question": "{{ $json.question }}",
    "brand_id": "9a933c7f-bd87-400f-b13a-b3bce7c822d8",
    "stream": true
  }
}
```

## Verzeichnisstruktur

```
brandchecker/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ python_app/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ llm_api.py              # LLM API Service
â”‚   â”œâ”€â”€ embedding_service.py    # OpenAI Embedding Service
â”‚   â”œâ”€â”€ brand_guidelines_importer.py
â”‚   â”œâ”€â”€ optimize_indexes.py     # Vector Index Optimierung
â”‚   â”œâ”€â”€ brand_compliance_analyzer.py  # Brand-Compliance-Analyzer (NEU!)
â”‚   â”œâ”€â”€ optimize_brand_data.py  # Daten-Optimierung (NEU!)
â”‚   â”œâ”€â”€ import_optimized_data.py  # Optimierte Daten-Import (NEU!)
â”‚   â”œâ”€â”€ reindex_optimized_data.py  # Master-Reindexierung (NEU!)
â”‚   â””â”€â”€ simple_optimize.py    # Einfache Daten-Optimierung (NEU!)
â”œâ”€â”€ postgres_init/
â”‚   â”œâ”€â”€ 01_init_database.sql
â”‚   â””â”€â”€ 02_brand_guidelines_schema.sql
â”œâ”€â”€ shared/
â”‚   â”œâ”€â”€ JSON/
â”‚   â”‚   â”œâ”€â”€ graphql.json        # Brand Guidelines Daten
â”‚   â”‚   â””â”€â”€ html.json
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ logos/
â”‚   â””â”€â”€ reports/
â”œâ”€â”€ test_llm_system.py          # LLM System Test
â”œâ”€â”€ LLM_SETUP_GUIDE.md          # Setup Anleitung
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## Hinweise

- Der n8n Service lÃ¤uft auf Port 5680 um Konflikte mit der bestehenden n8n Instanz auf Port 5678 zu vermeiden
- Alle Services teilen sich das `shared` Verzeichnis fÃ¼r Datenaustausch
- PDF-Dateien werden temporÃ¤r verarbeitet und automatisch gelÃ¶scht
- **LLM-Features erfordern einen gÃ¼ltigen OpenAI API Key**
- Brand Guidelines werden automatisch in die Datenbank importiert und mit Embeddings versehen
- **Farb-Ã„hnlichkeits-Bewertung** nutzt HSV-Algorithmen fÃ¼r prÃ¤zise Farb-Matching
- **Streaming-UnterstÃ¼tzung** ermÃ¶glicht Echtzeit-Antworten in n8n Workflows
- **Brand-Compliance-Analyzer** bietet automatische KonformitÃ¤tsbewertung mit 0-100 Punkte-System
- Vector-Indexes werden automatisch optimiert fÃ¼r optimale Suchperformance

## âš ï¸ WICHTIG fÃ¼r n8n Workflows:

**Verwende IMMER den Container-Namen statt localhost:**

**âŒ Falsch:** `http://localhost:8000/extract-fonts`
**âœ… Richtig:** `http://brandchecker-python:8000/extract-fonts`

**âŒ Falsch:** `http://localhost:8001/api/ask`
**âœ… Richtig:** `http://brandchecker-llm-api:8001/api/ask`

Siehe `N8N_SETUP_GUIDE.md` fÃ¼r detaillierte Anweisungen.

## ğŸ—ï¸ Architektur

Das System besteht aus mehreren Microservices:

- **ğŸ Python App** - Hauptanwendung mit KI-Analysen
- **ğŸ§  LLM API Service** - KI-gestÃ¼tzte Brand-Guideline-Befragung mit GPT-4o
- **ğŸ¨ Color Profile Service** - Farbanalyse und -extraktion
- **ğŸ”¤ Font Profile Service** - Font-Erkennung und -analyse
- **ğŸ–¼ï¸ Image Profile Service** - Bildverarbeitung und Logo-Detection
- **ğŸ“„ PDF Measure Service** - PDF-Layout und -Messungen
- **ğŸ—„ï¸ PostgreSQL mit pgvector** - Datenbank mit Vector Embeddings fÃ¼r semantische Suche
- **ğŸ”„ N8N** - Workflow-Automatisierung

## ğŸ“‹ Voraussetzungen

- Docker & Docker Compose
- Python 3.9+
- PostgreSQL 15+ mit pgvector Extension
- OpenAI API Key (fÃ¼r LLM-Features)
- N8N (optional)

## ğŸš€ Quick Start

```bash
# Repository klonen
git clone https://github.com/CHBRDK/brandchecker.git
cd brandchecker

# OpenAI API Key setzen (ERFORDERLICH fÃ¼r LLM-Features)
export OPENAI_API_KEY="your_openai_api_key_here"

# Services starten
docker-compose up -d

# Status prÃ¼fen
docker-compose ps

# LLM-System testen
python3 test_llm_system.py
```

### ğŸ”‘ Umgebungsvariablen

Erstelle eine `.env` Datei oder setze die folgenden Variablen:

```bash
# OpenAI API Key (ERFORDERLICH fÃ¼r LLM-Features)
OPENAI_API_KEY=your_openai_api_key_here

# LLM Model Konfiguration (optional, Standardwerte vorhanden)
EMBEDDING_MODEL=text-embedding-3-large
LLM_MODEL=gpt-5
EMBEDDING_DIMENSIONS=3072
FALLBACK_EMBEDDING_MODEL=text-embedding-3-small
FALLBACK_LLM_MODEL=gpt-4o

# PostgreSQL Konfiguration (optional, Standardwerte vorhanden)
POSTGRES_DB=brandchecker
POSTGRES_USER=brandchecker_user
POSTGRES_PASSWORD=brandchecker_password
```

## ğŸ“š Dokumentation

- **[LLM Setup Guide](LLM_SETUP_GUIDE.md)** - ğŸ†• VollstÃ¤ndige Anleitung fÃ¼r LLM-Integration
- [N8N Setup Guide](N8N_SETUP_GUIDE.md) - N8N Integration
- [Knowledge Database Integration](KNOWLEDGE_DATABASE_INTEGRATION.md) - KI-Datenbank
- [PostgreSQL Integration](POSTGRES_INTEGRATION.md) - Datenbank Setup
- [N8N Workflow Tutorial](N8N_WORKFLOW_TUTORIAL.md) - Workflow-Erstellung

### ğŸ§  LLM-Features im Detail

Das System bietet jetzt erweiterte KI-FunktionalitÃ¤ten:

1. **Semantische Suche** - Finde relevante Brand Guidelines mit natÃ¼rlicher Sprache
2. **Intelligente Befragung** - Stelle Fragen zu Brand Guidelines und erhalte kontextuelle Antworten
3. **Vector Embeddings** - Effiziente Ã„hnlichkeitssuche in groÃŸen Textmengen
4. **Automatische Compliance-Checks** - ÃœberprÃ¼fe Dokumente gegen Brand Guidelines
5. **N8N Integration** - Nutze LLM-Features in Workflows

## ğŸ¤ Contributing

1. Fork das Repository
2. Erstelle einen Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Committe deine Ã„nderungen (`git commit -m 'Add some AmazingFeature'`)
4. Push zum Branch (`git push origin feature/AmazingFeature`)
5. Ã–ffne eine Pull Request

## ğŸ“„ Lizenz

Dieses Projekt steht unter der MIT Lizenz. Siehe `LICENSE` fÃ¼r Details.

## ğŸ†˜ Support

Bei Fragen oder Problemen:
- Erstelle ein [Issue](https://github.com/CHBRDK/brandchecker/issues)
- Kontaktiere das Entwicklungsteam

---

â­ **Star dieses Repository, wenn es dir gefÃ¤llt!** 